1:"$Sreact.fragment"
2:I[5379,["850","static/chunks/850-de350858a22819d2.js","177","static/chunks/app/layout-30653af3c87d6211.js"],"ThemeProvider"]
3:I[1945,["850","static/chunks/850-de350858a22819d2.js","177","static/chunks/app/layout-30653af3c87d6211.js"],"default"]
4:I[9766,[],""]
5:I[8924,[],""]
7:I[4431,[],"OutletBoundary"]
9:I[5278,[],"AsyncMetadataOutlet"]
b:I[4431,[],"ViewportBoundary"]
d:I[4431,[],"MetadataBoundary"]
e:"$Sreact.suspense"
10:I[7150,[],""]
:HL["/_next/static/media/4cf2300e9c8272f7-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/886f446b96dc7734-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/9cf9c6e84ed13b5e-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/e693e841d50dcf2f-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/a7d7cda7084e7e71.css","style"]
0:{"P":null,"b":"9hS1bw4vLqB3Hrxjps2LV","p":"","c":["","publications"],"i":false,"f":[[["",{"children":["publications",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/a7d7cda7084e7e71.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_188709 __variable_9a8899 __variable_7dbc8c __className_e73cbf antialiased relative","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]}]}]]}],{"children":["publications",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":["$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Ld",null,{"children":["$","div",null,{"hidden":true,"children":["$","$e",null,{"fallback":null,"children":"$Lf"}]}]}]]}],false]],"m":"$undefined","G":["$10",[]],"s":false,"S":true}
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
11:I[622,[],"IconMark"]
a:{"metadata":[["$","title","0",{"children":"Create Next App"}],["$","meta","1",{"name":"description","content":"Generated by create next app"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","$L11","3",{}]],"error":null,"digest":"$undefined"}
f:"$a:metadata"
12:I[4057,["850","static/chunks/850-de350858a22819d2.js","352","static/chunks/app/publications/page-b592bbbaf126a7f6.js"],"default"]
6:["$","$L12",null,{"publications":[{"year":2023,"papers":[{"title":"Score-Guided Diffusion for 3D Human Recovery","authors":["A Stathopoulos","L Han","D Metaxas"],"date":"2024-01-01","id":"FdaFVdcAAAAJ:8k81kl-MbHgC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=FdaFVdcAAAAJ&pagesize=100&citation_for_view=FdaFVdcAAAAJ:8k81kl-MbHgC","publisher":"Computer Vision and Pattern Recognition (CVPR), 2024, 2024","venue":"CVPR"},{"title":"ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance","authors":["L Han","S Wen","Q Chen","Z Zhang","K Song","M Ren","R Gao","A Stathopoulos","..."],"date":"2024-01-01","id":"FdaFVdcAAAAJ:0EnyYjriUFMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=FdaFVdcAAAAJ&pagesize=100&citation_for_view=FdaFVdcAAAAJ:0EnyYjriUFMC","publisher":"Winter Conference on Applications of Computer Vision (WACV), 2024, 2024","venue":"WACV"},{"title":"Layout-agnostic scene text image synthesis with diffusion models","authors":["Q Zhangli","J Jiang","D Liu","L Yu","X Dai","A Ramchandani","G Pang","..."],"date":"2024-01-01","id":"sLxp0xAAAAAJ:Y0pCki6q_DkC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sLxp0xAAAAAJ&pagesize=100&citation_for_view=sLxp0xAAAAAJ:Y0pCki6q_DkC","publisher":"2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR …, 2024","venue":"CVPR"},{"title":"Implicit In-context Learning","authors":["Z Li","Z Xu","L Han","Y Gao","S Wen","D Liu","H Wang","DN Metaxas"],"date":"2024-01-01","id":"TOsFPu4AAAAJ:0EnyYjriUFMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TOsFPu4AAAAJ&pagesize=100&citation_for_view=TOsFPu4AAAAJ:0EnyYjriUFMC","publisher":"The Thirteenth International Conference on Learning Representations (ICLR), 2025, 2024","venue":"ICLR"},{"title":"SINE: Single image editing with text-to-image diffusion models","authors":["Z Zhang","L Han","A Ghosh","DN Metaxas","J Ren"],"date":"2023-01-01","id":"RhM5qHoAAAAJ:IjCSPb-OGe4C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:IjCSPb-OGe4C","publisher":"CVPR 2023, 2023","venue":"CVPR"},{"title":"Omnilabel: A challenging benchmark for language-based object detection","authors":["S Schulter","Y Suh","KM Dafnis","Z Zhang","S Zhao","D Metaxas"],"date":"2023-01-01","id":"RhM5qHoAAAAJ:UebtZRa9Y70C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:UebtZRa9Y70C","publisher":"ICCV 2023, 2023","venue":"ICCV"},{"title":"OmniLabel: A Challenging Benchmark for Language-Based Object Detection","authors":["S Schulter","VK B G","Y Suh","KM Dafnis","Z Zhang","S Zhao","D Metaxas"],"date":"2023-01-01","id":"M-qzlU8AAAAJ:ufrVoPGSRksC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M-qzlU8AAAAJ&pagesize=100&citation_for_view=M-qzlU8AAAAJ:ufrVoPGSRksC","publisher":"ICCV 2023, 2023","venue":"ICCV"},{"title":"LEPARD: Learning Explicit Part Discovery for 3D Articulated Shape Reconstruction","authors":["D Liu","Q Zhangli","Y Gao","DN Metaxas"],"date":"2023-01-01","id":"1uo3XsMAAAAJ:8k81kl-MbHgC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:8k81kl-MbHgC","publisher":"NeurIPS 2023, 2023","venue":"NeurIPS"},{"title":"Deformer: Integrating transformers with deformable models for 3d shape abstraction from a single image","authors":["D Liu","X Yu","M Ye","Q Zhangli","Z Li","Z Zhang","DN Metaxas"],"date":"2023-01-01","id":"RhM5qHoAAAAJ:LkGwnXOMwfcC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:LkGwnXOMwfcC","publisher":"ICCV 2023, 2023","venue":"ICCV"},{"title":"Deformer: Integrating transformers with deformable models for 3d shape abstraction from a single image","authors":["D Liu","X Yu","M Ye","Q Zhangli","Z Li","Z Zhang","DN Metaxas"],"date":"2023-01-01","id":"51OJEPcAAAAJ:Tyk-4Ss8FVUC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:Tyk-4Ss8FVUC","publisher":"IEEE/CVF International Conference on Computer Vision (ICCV 2023), 2023","venue":"ICCV"},{"title":"DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image","authors":["D Liu","X Yu","M Ye","Q Zhangli","Z Li","Z Zhang","DN Metaxas"],"date":"2023-01-01","id":"1uo3XsMAAAAJ:KlAtU1dfN6UC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:KlAtU1dfN6UC","publisher":"ICCV 2023, 2023","venue":"ICCV"}]},{"year":2024,"papers":[{"title":"SODA: Spectral Orthogonal Decomposition Adaptation for Diffusion Models","authors":["X Zhang","S Wen","L Han","F Juefei-Xu","A Srivastava","J Huang","V Pavlovic","..."],"date":"2025-01-01","id":"yTQbz6AAAAAJ:mVmsd5A6BfQC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTQbz6AAAAAJ&pagesize=100&citation_for_view=yTQbz6AAAAAJ:mVmsd5A6BfQC","publisher":"2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV …, 2025","venue":"WACV"},{"title":"SODA: Spectral Orthogonal Decomposition Adaptation for Diffusion Models","authors":["X Zhang*","S Wen*","L Han*†","F Juefei-Xu","A Srivastava","J Huang","..."],"date":"2025-01-01","id":"n2v43R4AAAAJ:35N4QoGY0k4C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n2v43R4AAAAJ&pagesize=100&citation_for_view=n2v43R4AAAAJ:35N4QoGY0k4C","publisher":"2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV …, 2025","venue":"WACV"},{"title":"SF-V: Single forward video generation model","authors":["Z Zhang","Y Li","Y Wu","A Kag","I Skorokhodov","W Menapace","A Siarohin","..."],"date":"2025-01-01","id":"RhM5qHoAAAAJ:9ZlFYXVOiuMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:9ZlFYXVOiuMC","publisher":"NeurIPS 2024, 2025","venue":"NeurIPS"},{"title":"K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical Image Segmentation Model","authors":["B Guo","Y Gao","M Ye","D Gu","Y Zhou","L Axel","D Metaxas"],"date":"2025-01-01","id":"TOsFPu4AAAAJ:7PzlFSSx8tAC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TOsFPu4AAAAJ&pagesize=100&citation_for_view=TOsFPu4AAAAJ:7PzlFSSx8tAC","publisher":"The Fourteenth International Conference on Learning Representations (ICLR), 2026, 2025","venue":"ICLR"},{"title":"Continuous Spatio-Temporal Memory Networks for 4D Cardiac Cine MRI Segmentation","authors":["M Ye","B Xin","L Axel","D Metaxas"],"date":"2025-01-01","id":"iYBbF7QAAAAJ:LkGwnXOMwfcC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iYBbF7QAAAAJ&pagesize=100&citation_for_view=iYBbF7QAAAAJ:LkGwnXOMwfcC","publisher":"2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV …, 2025","venue":"WACV"},{"title":"Training Like a Medical Resident: Context-Prior Learning Toward Universal Medical Image Segmentation","authors":["Y Gao","Z Li","D Liu","M Zhou","S Zhang","DN Metaxas"],"date":"2024-01-01","id":"1uo3XsMAAAAJ:UebtZRa9Y70C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:UebtZRa9Y70C","publisher":"CVPR 2024, 2024","venue":"CVPR"},{"title":"Taming self-training for open-vocabulary object detection","authors":["S Zhao","S Schulter","L Zhao","Z Zhang","Y Suh","M Chandraker","DN Metaxas"],"date":"2024-01-01","id":"RhM5qHoAAAAJ:7PzlFSSx8tAC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:7PzlFSSx8tAC","publisher":"CVPR 2024, 2024","venue":"CVPR"},{"title":"Steering prototypes with prompt-tuning for rehearsal-free continual learning","authors":["Z Li","L Zhao","Z Zhang","H Zhang","D Liu","T Liu","DN Metaxas"],"date":"2024-01-01","id":"1uo3XsMAAAAJ:ufrVoPGSRksC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:ufrVoPGSRksC","publisher":"WACV 2024, 2024","venue":"WACV"},{"title":"Steering prototypes with prompt-tuning for rehearsal-free continual learning","authors":["Z Li","L Zhao","Z Zhang","H Zhang","D Liu","T Liu","DN Metaxas"],"date":"2024-01-01","id":"51OJEPcAAAAJ:IjCSPb-OGe4C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:IjCSPb-OGe4C","publisher":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024 …, 2024","venue":"WACV"},{"title":"Second-order graph odes for multi-agent trajectory forecasting","authors":["S Wen","H Wang","D Liu","Q Zhangli","D Metaxas"],"date":"2024-01-01","id":"1uo3XsMAAAAJ:Zph67rFs4hoC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:Zph67rFs4hoC","publisher":"WACV 2024, 2024","venue":"WACV"},{"title":"Proxedit: Improving tuning-free real image editing with proximal guidance","authors":["L Han","S Wen","Q Chen","Z Zhang","K Song","M Ren","R Gao","A Stathopoulos","..."],"date":"2024-01-01","id":"1uo3XsMAAAAJ:YOwf2qJgpHMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:YOwf2qJgpHMC","publisher":"WACV 2024, 2024","venue":"WACV"},{"title":"Proxedit: Improving tuning-free real image editing with proximal guidance","authors":["L Han","S Wen","Q Chen","Z Zhang","K Song","M Ren","R Gao","A Stathopoulos","..."],"date":"2024-01-01","id":"RhM5qHoAAAAJ:MXK_kJrjxJIC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:MXK_kJrjxJIC","publisher":"WACV 2024, 2024","venue":"WACV"},{"title":"Layout-Agnostic Scene Text Image Synthesis with Diffusion Models","authors":["Q Zhangli","J Jiang","D Liu","L Yu","X Dai","A Ramchandani","G Pang","..."],"date":"2024-01-01","id":"1uo3XsMAAAAJ:qxL8FJ1GzNcC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:qxL8FJ1GzNcC","publisher":"CVPR 2024, 2024","venue":"CVPR"},{"title":"Instantaneous Perception of Moving Objects in 3D","authors":["D Liu","B Zhuang","DN Metaxas","M Chandraker"],"date":"2024-01-01","id":"1uo3XsMAAAAJ:4TOpqqG69KYC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:4TOpqqG69KYC","publisher":"CVPR 2024, 2024","venue":"CVPR"},{"title":"Finding needles in a haystack: A Black-Box Approach to Invisible Watermark Detection","authors":["M Pan","Z Wang","X Dong","V Sehwag","L Lyu","X Lin"],"date":"2024-01-01","id":"QSYVbj8AAAAJ:0EnyYjriUFMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:0EnyYjriUFMC","publisher":"The 18th European Conference on Computer Vision (ECCV 2024), 2024","venue":"ECCV"},{"title":"AVID: Any-length video inpainting with diffusion model","authors":["Z Zhang","B Wu","X Wang","Y Luo","L Zhang","Y Zhao","P Vajda","D Metaxas","..."],"date":"2024-01-01","id":"RhM5qHoAAAAJ:dhFuZR0502QC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:dhFuZR0502QC","publisher":"CVPR 2024, 2024","venue":"CVPR"},{"title":"Training like a medical resident: universal medical image segmentation via context prior learning","authors":["Y Gao","Z Li","D Liu","M Zhou","S Zhang","DN Meta"],"date":"2023-01-01","id":"51OJEPcAAAAJ:zYLM7Y9cAGgC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:zYLM7Y9cAGgC","publisher":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024), 2023","venue":"CVPR"}]},{"year":2025,"papers":[{"title":"The hidden life of tokens: Reducing hallucination of large vision-language models via visual information steering","authors":["Z Li","H Shi","Y Gao","D Liu","Z Wang","Y Chen","T Liu","L Zhao","H Wang","..."],"date":"2025-01-01","id":"51OJEPcAAAAJ:ufrVoPGSRksC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:ufrVoPGSRksC","publisher":"International Conference on Machine Learning (ICML 2025), 2025","venue":"ICML"},{"title":"The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering","authors":["Z Li","H Shi","Y Gao","D Liu","Z Wang","Y Chen","T Liu","L Zhao","H Wang","..."],"date":"2025-01-01","id":"QSYVbj8AAAAJ:maZDTaKrznsC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:maZDTaKrznsC","publisher":"ICML 2025, 2025","venue":"ICML"},{"title":"The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering","authors":["Z Li","H Shi","Y Gao","D Liu","Z Wang","Y Chen","T Liu","L Zhao","H Wang","..."],"date":"2025-01-01","id":"1uo3XsMAAAAJ:hC7cP41nSMkC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:hC7cP41nSMkC","publisher":"ICML 2025, 2025","venue":"ICML"},{"title":"T2Bs: Text-to-Character Blendshapes via Video Generation","authors":["J Luo","C Wang","M Vasilkovsky","V Shakhrai","D Liu","P Zhuang","S Tulyakov","..."],"date":"2025-01-01","id":"1uo3XsMAAAAJ:TFP_iSt0sucC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:TFP_iSt0sucC","publisher":"ICCV 2025, 2025","venue":"ICCV"},{"title":"Snapgen-v: Generating a five-second video within five seconds on a mobile device","authors":["Y Wu*","Z Zhang*","Y Li*","Y Xu","A Kag","Y Sui","H Coskun","K Ma","A Lebedev","..."],"date":"2025-01-01","id":"RhM5qHoAAAAJ:ZeXyd9-uunAC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhM5qHoAAAAJ&pagesize=100&citation_for_view=RhM5qHoAAAAJ:ZeXyd9-uunAC","publisher":"CVPR 2025, 2025","venue":"CVPR"},{"title":"Show and Segment: Universal Medical Image Segmentation via In-Context Learning","authors":["Y Gao","D Liu","Z Li","Y Li","D Chen","M Zhou","DN Metaxas"],"date":"2025-01-01","id":"1uo3XsMAAAAJ:mB3voiENLucC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:mB3voiENLucC","publisher":"CVPR 2025, 2025","venue":"CVPR"},{"title":"Show and Segment: Universal Medical Image Segmentation via In-Context Learning","authors":["Y Gao","D Liu","Z Li","Y Li","D Chen","M Zhou","DN Metaxas"],"date":"2025-01-01","id":"51OJEPcAAAAJ:hqOjcs7Dif8C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:hqOjcs7Dif8C","publisher":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025), 2025","venue":"CVPR"},{"title":"Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing","authors":["Z Li","T Zhao","X Xu","Z Zhang","Z Li","X Chen","Q Zhang","A Bergamo","AK Jain","..."],"date":"2025-01-01","id":"51OJEPcAAAAJ:5nxA0vEk-isC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:5nxA0vEk-isC","publisher":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025), 2025","venue":"CVPR"},{"title":"LoR-VP: Low-Rank Visual Prompting for Efficient Vision Model Adaptation","authors":["C Jin","Y Li","M Zhao","S Zhao","Z Wang","X He","L Han","T Che","DN Metaxas"],"date":"2025-01-01","id":"QSYVbj8AAAAJ:k_IJM867U9cC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:k_IJM867U9cC","publisher":"ICLR 2025, 2025","venue":"ICLR"},{"title":"LUCAS: Layered Universal Codec Avatars","authors":["D Liu","T Deng","G Nam","Y Rong","S Pidhorskyi","J Li","J Saragih","DN Metaxas","..."],"date":"2025-01-01","id":"1uo3XsMAAAAJ:_Qo2XoVZTnwC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:_Qo2XoVZTnwC","publisher":"CVPR 2025, 2025","venue":"CVPR"},{"title":"Invisible Backdoor Attack against Self-supervised Learning","authors":["H Zhang*","Z Wang*","B Li","F Lin","T Han","M Jin","C Zhan","M Du","H Wang","..."],"date":"2025-01-01","id":"QSYVbj8AAAAJ:J_g5lzvAfSwC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:J_g5lzvAfSwC","publisher":"CVPR 2025 (* indicates equal contributions), 25790-25801, 2025","venue":"CVPR"},{"title":"Improved Training Technique for Latent Consistency Models","authors":["Q Dao","K Doan","D Liu","T Le","D Metaxas"],"date":"2025-01-01","id":"1uo3XsMAAAAJ:qUcmZB5y_30C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:qUcmZB5y_30C","publisher":"ICLR 2025, 2025","venue":"ICLR"},{"title":"Implicit In-context Learning","authors":["Z Li","Z Xu","L Han","Y Gao","S Wen","D Liu","H Wang","DN Metaxas"],"date":"2025-01-01","id":"1uo3XsMAAAAJ:4DMP91E08xMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1uo3XsMAAAAJ&pagesize=100&citation_for_view=1uo3XsMAAAAJ:4DMP91E08xMC","publisher":"ICLR 2025, 2025","venue":"ICLR"},{"title":"Continuous Concepts Removal in Text-to-image Diffusion Models","authors":["T Han","W Sun","Y Hu","C Fang","Y Zhang","S Ma","T Zheng","Z Chen","Z Wang"],"date":"2025-01-01","id":"QSYVbj8AAAAJ:4JMBOYKVnBMC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:4JMBOYKVnBMC","publisher":"NeurIPS 2025, 2025","venue":"NeurIPS"},{"title":"CO-SPY: Combining Semantic and Pixel Features to Detect Synthetic Images by AI","authors":["S Cheng","L Lyu","Z Wang","X Zhang","V Sehwag"],"date":"2025-01-01","id":"QSYVbj8AAAAJ:GnPB-g6toBAC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:GnPB-g6toBAC","publisher":"CVPR 2025, 2025","venue":"CVPR"},{"title":"Visual Agents as Fast and Slow Thinkers","authors":["G Sun","M Jin","Z Wang","CL Wang","S Ma","Q Wang","YN Wu","Y Zhang","D Liu"],"date":"2024-01-01","id":"QSYVbj8AAAAJ:Wp0gIr-vW9MC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:Wp0gIr-vW9MC","publisher":"ICLR 2025, 2024","venue":"ICLR"},{"title":"ProSec: Fortifying Code LLMs with Proactive Security Alignment","authors":["X Xu","Z Su","J Guo","K Zhang","Z Wang","X Zhang"],"date":"2024-01-01","id":"QSYVbj8AAAAJ:HDshCWvjkbEC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:HDshCWvjkbEC","publisher":"ICML 2025, 2024","venue":"ICML"},{"title":"MLLM-as-a-Judge for Image Safety without Human Labeling","authors":["Z Wang","S Hu","S Zhao","X Lin","F Juefei-Xu","Z Li","L Han","H Subramanyam","..."],"date":"2024-01-01","id":"QSYVbj8AAAAJ:bEWYMUwI8FkC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:bEWYMUwI8FkC","publisher":"CVPR 2025, 2024","venue":"CVPR"},{"title":"MLLM-as-a-Judge for Image Safety without Human Labeling","authors":["Z Wang","S Hu","S Zhao","X Lin","F Juefei-Xu","Z Li","L Han","H Subramanyam","..."],"date":"2024-01-01","id":"M-qzlU8AAAAJ:kNdYIx-mwKoC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M-qzlU8AAAAJ&pagesize=100&citation_for_view=M-qzlU8AAAAJ:kNdYIx-mwKoC","publisher":"CVPR 2025, 2024","venue":"CVPR"},{"title":"MLLM-as-a-Judge for Image Safety without Human Labeling","authors":["Z Wang","S Hu","S Zhao","X Lin","F Juefei-Xu","Z Li","L Han","H Subramanyam","..."],"date":"2024-01-01","id":"51OJEPcAAAAJ:WF5omc3nYNoC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:WF5omc3nYNoC","publisher":"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025), 2024","venue":"CVPR"},{"title":"Implicit In-context Learning","authors":["Z Li","Z Xu","L Han","Y Gao","S Wen","D Liu","H Wang","DN Metaxas"],"date":"2024-01-01","id":"51OJEPcAAAAJ:UebtZRa9Y70C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=51OJEPcAAAAJ&pagesize=100&citation_for_view=51OJEPcAAAAJ:UebtZRa9Y70C","publisher":"The Thirteenth International Conference on Learning Representations (ICLR 2025), 2024","venue":"ICLR"},{"title":"Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents","authors":["H Zhang","J Huang","K Mei","Y Yao","Z Wang","C Zhan","H Wang","Y Zhang"],"date":"2024-01-01","id":"QSYVbj8AAAAJ:IWHjjKOFINEC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:IWHjjKOFINEC","publisher":"ICLR 2025, 2024","venue":"ICLR"},{"title":"Accelerating Multimodal Large Language Models by Searching Optimal Vision Token Reduction","authors":["S Zhao","Z Wang","F Juefei-Xu","X Xia","M Liu","X Wang","M Liang","N Zhang","..."],"date":"2024-01-01","id":"QSYVbj8AAAAJ:j3f4tGmQtD8C","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QSYVbj8AAAAJ&pagesize=100&citation_for_view=QSYVbj8AAAAJ:j3f4tGmQtD8C","publisher":"CVPR 2025, 2024","venue":"CVPR"},{"title":"Accelerating Multimodal Large Language Models by Searching Optimal Vision Token Reduction","authors":["S Zhao","Z Wang","F Juefei-Xu","X Xia","M Liu","X Wang","M Liang","N Zhang","..."],"date":"2024-01-01","id":"M-qzlU8AAAAJ:MXK_kJrjxJIC","link":"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M-qzlU8AAAAJ&pagesize=100&citation_for_view=M-qzlU8AAAAJ:MXK_kJrjxJIC","publisher":"CVPR 2025, 2024","venue":"CVPR"}]}]}]
